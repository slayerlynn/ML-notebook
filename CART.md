# CART 决策树模型

## 1. 基本概念
CART(CLASSIFICATION AND REGRESSION TREE)是一种二叉树模型,是有监督的机器学习模型，对于分类和回归两种任务，通过解决最优化问题如MSE、基尼系数、信息增益和信息增益比来实现数据的划分和预测。
- 分类树
  给定特征 𝑋，预测类别标签 𝑦，如（是/否，高/中/低）等标签。
  损失函数主要使用**基尼系数**或**信息增量**。
  
  $$
  Gini = 1 - \sum p_k^2
  $$

  $$
  Gain(D, A) = Entropy(D) - \sum_{v=1}^{V} \frac{|D_v|}{|D|} Entropy(D_v)
  $$
  
- 回归树
  给定特征*X*,预测连续变量*y*。
  损失函数主要使用**MSE**。

$$
MSE=\frac{1}{V} \sum_{v=1}^{V}(y_v-\hat{y}_v)^2
$$

## 2. 损失函数
- 基尼系数（二分类）

$$
Gini = 1 - \sum p_k^2
$$

GAIN = 
- sigmoid(二分类）

  Sigmoid函数（逻辑回归激活函数）

$$p(x) = \sigma(f(x)) = \frac{1}{1 + e^{-f(x)}}$$


| 符号          | 名称/含义                                                                 |
|---------------|--------------------------------------------------------------------------|
| $\sigma(\cdot)$ | Sigmoid激活函数符号，本质是一种“压缩函数”                                 |
| $p(x)$         | 函数输出值，范围为 **[0, 1]**，常用于二分类任务中表示“样本属于正类的概率” |
| $f(x)$         | 线性回归模型的输出，计算公式为：<br>$f(x) = w_1x_1 + w_2x_2 + ... + w_nx_n + b$ |
| $w_n$          | 特征权重，对应第$n$个特征$x_n$的重要性系数                               |
| $x_n$          | 模型输入的第$n$个特征（如数据集中的单个属性）                            |
| $b$            | 偏置项（截距），用于调整模型的基础输出水平，避免仅依赖特征值              |
| $e$            | 自然常数，约等于2.718，此处通过$e^{-f(x)}$实现对输入值的范围压缩        |

- MSE（回归）

$$
MSE=\frac{1}{V} \sum_{v=1}^{V}(y_v-\hat{y}_v)^2
$$
  
- 交叉熵+softmax(多分类）
  

## 3. 构建流程
1. 选择最优划分点
2. 递归生成子树
3. 剪枝优化


